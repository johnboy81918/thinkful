{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 17 Checkpoint 3 (Data cleaning 2: missing values) Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by loading the remote database into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'useducation'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "education_df = pd.read_sql_query('select * from useducation',con=engine)\n",
    "\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine all the variable types and find the fraction of the missing values for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1492 entries, 0 to 1491\n",
      "Data columns (total 25 columns):\n",
      "PRIMARY_KEY                     1492 non-null object\n",
      "STATE                           1492 non-null object\n",
      "YEAR                            1492 non-null int64\n",
      "ENROLL                          1229 non-null float64\n",
      "TOTAL_REVENUE                   1280 non-null float64\n",
      "FEDERAL_REVENUE                 1280 non-null float64\n",
      "STATE_REVENUE                   1280 non-null float64\n",
      "LOCAL_REVENUE                   1280 non-null float64\n",
      "TOTAL_EXPENDITURE               1280 non-null float64\n",
      "INSTRUCTION_EXPENDITURE         1280 non-null float64\n",
      "SUPPORT_SERVICES_EXPENDITURE    1280 non-null float64\n",
      "OTHER_EXPENDITURE               1229 non-null float64\n",
      "CAPITAL_OUTLAY_EXPENDITURE      1280 non-null float64\n",
      "GRADES_PK_G                     1319 non-null float64\n",
      "GRADES_KG_G                     1360 non-null float64\n",
      "GRADES_4_G                      1361 non-null float64\n",
      "GRADES_8_G                      1361 non-null float64\n",
      "GRADES_12_G                     1361 non-null float64\n",
      "GRADES_1_8_G                    1361 non-null float64\n",
      "GRADES_9_12_G                   1361 non-null float64\n",
      "GRADES_ALL_G                    1319 non-null float64\n",
      "AVG_MATH_4_SCORE                536 non-null float64\n",
      "AVG_MATH_8_SCORE                532 non-null float64\n",
      "AVG_READING_4_SCORE             533 non-null float64\n",
      "AVG_READING_8_SCORE             498 non-null float64\n",
      "dtypes: float64(22), int64(1), object(2)\n",
      "memory usage: 279.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Determine variable types:\n",
    "education_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY                     0.000000\n",
       "STATE                           0.000000\n",
       "YEAR                            0.000000\n",
       "ENROLL                          0.176273\n",
       "TOTAL_REVENUE                   0.142091\n",
       "FEDERAL_REVENUE                 0.142091\n",
       "STATE_REVENUE                   0.142091\n",
       "LOCAL_REVENUE                   0.142091\n",
       "TOTAL_EXPENDITURE               0.142091\n",
       "INSTRUCTION_EXPENDITURE         0.142091\n",
       "SUPPORT_SERVICES_EXPENDITURE    0.142091\n",
       "OTHER_EXPENDITURE               0.176273\n",
       "CAPITAL_OUTLAY_EXPENDITURE      0.142091\n",
       "GRADES_PK_G                     0.115952\n",
       "GRADES_KG_G                     0.088472\n",
       "GRADES_4_G                      0.087802\n",
       "GRADES_8_G                      0.087802\n",
       "GRADES_12_G                     0.087802\n",
       "GRADES_1_8_G                    0.087802\n",
       "GRADES_9_12_G                   0.087802\n",
       "GRADES_ALL_G                    0.115952\n",
       "AVG_MATH_4_SCORE                0.640751\n",
       "AVG_MATH_8_SCORE                0.643432\n",
       "AVG_READING_4_SCORE             0.642761\n",
       "AVG_READING_8_SCORE             0.666220\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the fraction of missing values:\n",
    "education_df.isnull().sum()/education_df.isnull().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notice that the data has a time dimension (year). For this assignment, forget about time and treat all the observations as if they're from the same year. Choose a strategy to deal with the missing values for each variables. For which variables would filling in the missing values with some value make sense? For which might tossing out the records entirely make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most useful variables that can be filled in are the those that are numeric (floats) and *not* already aggregated (i.e. the final 4 variables appear to be averages). Depending on how the data is organized (check if it appears to be already sorted by year and/or state), records with blank year and/or state values may need to be discarded, since they would be difficult to accurately impute if the data is arranged randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate the dataframe in case I do something stupid, so the original remains intact.\n",
    "educationdup_df = education_df.copy()\n",
    "\n",
    "# Determine which columns to apply imputation to (the non-aggregated floats)\n",
    "imputable_columns = [\"ENROLL\", \"TOTAL_REVENUE\", \"FEDERAL_REVENUE\", \n",
    "             \"STATE_REVENUE\", \"LOCAL_REVENUE\", \"TOTAL_EXPENDITURE\", \n",
    "             \"INSTRUCTION_EXPENDITURE\", \"SUPPORT_SERVICES_EXPENDITURE\",\n",
    "             \"OTHER_EXPENDITURE\", \"CAPITAL_OUTLAY_EXPENDITURE\", \"GRADES_PK_G\", \n",
    "             \"GRADES_KG_G\", \"GRADES_4_G\", \"GRADES_8_G\", \"GRADES_12_G\", \"GRADES_1_8_G\", \n",
    "             \"GRADES_9_12_G\", \"GRADES_ALL_G\"]\n",
    "\n",
    "# For each column selected, replace all null values with the mean (aggregated over the entire column)\n",
    "for column in imputable_columns:\n",
    "    educationdup_df.loc[:, column].fillna(educationdup_df.loc[:, column].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, take into account the time factor. Replicate your second answer but this time fill in the missing values by using a statistic that is calculated within the year of the observation. For example, if you want to fill a missing value for a variable with the mean of that variable, calculate the mean by using only the observations for that specific year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new duplicate to store this attempt\n",
    "educationdup2_df = education_df.copy()\n",
    "\n",
    "# Find all unique year values to iterate over\n",
    "years = educationdup2_df[\"YEAR\"].unique()\n",
    "\n",
    "# In each column, for each year, fill nulls with the mean of that specific year\n",
    "for column in imputable_columns:\n",
    "    for year in years:\n",
    "        educationdup2_df.loc[educationdup2_df[\"YEAR\"] == year, column].fillna(\n",
    "            educationdup2_df[educationdup2_df[\"YEAR\"] == year][column].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This time, fill in the missing values using interpolation (extrapolation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another storage duplicate\n",
    "educationdup3_df = education_df.copy()\n",
    "\n",
    "# Use interpolation (with default settings because I don't know how to really use this yet!)\n",
    "for column in imputable_columns:\n",
    "    educationdup3_df.loc[:, column].interpolate(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare your results for the second, third and the fourth questions. Do you find any meaningful differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare basic statistics for each of the 3 dataframes that has been modified from the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for columns: ENROLL\n",
      "             ENROLL        ENROLL        ENROLL\n",
      "count  1.492000e+03  1.229000e+03  1.456000e+03\n",
      "mean   9.159308e+05  9.159308e+05  1.005984e+06\n",
      "std    9.667725e+05  1.065280e+06  1.009158e+06\n",
      "min    4.386600e+04  4.386600e+04  4.386600e+04\n",
      "25%    3.150940e+05  2.583140e+05  2.973995e+05\n",
      "50%    8.204140e+05  6.483130e+05  7.540845e+05\n",
      "75%    9.211780e+05  1.014528e+06  1.595024e+06\n",
      "max    6.307022e+06  6.307022e+06  6.307022e+06\n",
      "Statistics for columns: TOTAL_REVENUE\n",
      "       TOTAL_REVENUE  TOTAL_REVENUE  TOTAL_REVENUE\n",
      "count   1.492000e+03   1.280000e+03   1.492000e+03\n",
      "mean    9.092082e+06   9.092082e+06   1.111164e+07\n",
      "std     1.087818e+07   1.174519e+07   1.200155e+07\n",
      "min     4.656500e+05   4.656500e+05   4.656500e+05\n",
      "25%     2.546261e+06   2.186305e+06   2.546261e+06\n",
      "50%     6.359310e+06   5.079546e+06   6.351760e+06\n",
      "75%     9.276958e+06   1.085985e+07   1.803650e+07\n",
      "max     8.921726e+07   8.921726e+07   8.921726e+07\n",
      "Statistics for columns: FEDERAL_REVENUE\n",
      "       FEDERAL_REVENUE  FEDERAL_REVENUE  FEDERAL_REVENUE\n",
      "count     1.492000e+03     1.280000e+03     1.492000e+03\n",
      "mean      7.663723e+05     7.663723e+05     8.922691e+05\n",
      "std       1.060702e+06     1.145242e+06     1.106788e+06\n",
      "min       3.102000e+04     3.102000e+04     3.102000e+04\n",
      "25%       2.170200e+05     1.893540e+05     2.170200e+05\n",
      "50%       5.167410e+05     4.033765e+05     5.165190e+05\n",
      "75%       7.663723e+05     8.289660e+05     1.411794e+06\n",
      "max       9.990221e+06     9.990221e+06     9.990221e+06\n",
      "Statistics for columns: STATE_REVENUE\n",
      "       STATE_REVENUE  STATE_REVENUE  STATE_REVENUE\n",
      "count   1.492000e+03   1.280000e+03   1.492000e+03\n",
      "mean    4.216553e+06   4.216553e+06   4.913351e+06\n",
      "std     5.133895e+06   5.543072e+06   5.423675e+06\n",
      "min     0.000000e+00   0.000000e+00   0.000000e+00\n",
      "25%     1.356434e+06   1.153097e+06   1.356434e+06\n",
      "50%     3.127639e+06   2.537074e+06   3.119414e+06\n",
      "75%     4.269811e+06   5.080939e+06   8.020633e+06\n",
      "max     5.090457e+07   5.090457e+07   5.090457e+07\n",
      "Statistics for columns: LOCAL_REVENUE\n",
      "       LOCAL_REVENUE  LOCAL_REVENUE  LOCAL_REVENUE\n",
      "count   1.492000e+03   1.280000e+03   1.492000e+03\n",
      "mean    4.109157e+06   4.109157e+06   5.306024e+06\n",
      "std     5.078230e+06   5.482971e+06   5.900909e+06\n",
      "min     2.209300e+04   2.209300e+04   2.209300e+04\n",
      "25%     9.447962e+05   7.158345e+05   9.447962e+05\n",
      "50%     2.697257e+06   2.055780e+06   2.650904e+06\n",
      "75%     4.109157e+06   4.768680e+06   8.584803e+06\n",
      "max     3.610526e+07   3.610526e+07   3.610526e+07\n",
      "Statistics for columns: TOTAL_EXPENDITURE\n",
      "       TOTAL_EXPENDITURE  TOTAL_EXPENDITURE  TOTAL_EXPENDITURE\n",
      "count       1.492000e+03       1.280000e+03       1.492000e+03\n",
      "mean        9.196681e+06       9.196681e+06       1.114374e+07\n",
      "std         1.109393e+07       1.197813e+07       1.212433e+07\n",
      "min         4.816650e+05       4.816650e+05       4.816650e+05\n",
      "25%         2.523968e+06       2.165404e+06       2.523968e+06\n",
      "50%         6.520224e+06       5.234506e+06       6.499891e+06\n",
      "75%         9.434922e+06       1.074519e+07       1.801704e+07\n",
      "max         8.532013e+07       8.532013e+07       8.532013e+07\n",
      "Statistics for columns: INSTRUCTION_EXPENDITURE\n",
      "       INSTRUCTION_EXPENDITURE  INSTRUCTION_EXPENDITURE  \\\n",
      "count             1.492000e+03             1.280000e+03   \n",
      "mean              4.762966e+06             4.762966e+06   \n",
      "std               5.828468e+06             6.293004e+06   \n",
      "min               2.655490e+05             2.655490e+05   \n",
      "25%               1.343611e+06             1.168032e+06   \n",
      "50%               3.358142e+06             2.657452e+06   \n",
      "75%               4.938820e+06             5.568028e+06   \n",
      "max               4.396452e+07             4.396452e+07   \n",
      "\n",
      "       INSTRUCTION_EXPENDITURE  \n",
      "count             1.492000e+03  \n",
      "mean              5.792260e+06  \n",
      "std               6.376549e+06  \n",
      "min               2.655490e+05  \n",
      "25%               1.343611e+06  \n",
      "50%               3.318778e+06  \n",
      "75%               9.130766e+06  \n",
      "max               4.396452e+07  \n",
      "Statistics for columns: SUPPORT_SERVICES_EXPENDITURE\n",
      "       SUPPORT_SERVICES_EXPENDITURE  SUPPORT_SERVICES_EXPENDITURE  \\\n",
      "count                  1.492000e+03                  1.280000e+03   \n",
      "mean                   2.680331e+06                  2.680331e+06   \n",
      "std                    3.105812e+06                  3.353349e+06   \n",
      "min                    1.399630e+05                  1.399630e+05   \n",
      "25%                    7.673688e+05                  6.357900e+05   \n",
      "50%                    1.913844e+06                  1.525406e+06   \n",
      "75%                    2.795888e+06                  3.229651e+06   \n",
      "max                    2.605802e+07                  2.605802e+07   \n",
      "\n",
      "       SUPPORT_SERVICES_EXPENDITURE  \n",
      "count                  1.492000e+03  \n",
      "mean                   3.324275e+06  \n",
      "std                    3.500830e+06  \n",
      "min                    1.399630e+05  \n",
      "25%                    7.673688e+05  \n",
      "50%                    1.910412e+06  \n",
      "75%                    5.435244e+06  \n",
      "max                    2.605802e+07  \n",
      "Statistics for columns: OTHER_EXPENDITURE\n",
      "       OTHER_EXPENDITURE  OTHER_EXPENDITURE  OTHER_EXPENDITURE\n",
      "count       1.492000e+03       1.229000e+03       1.456000e+03\n",
      "mean        4.292046e+05       4.292046e+05       5.004288e+05\n",
      "std         4.846832e+05       5.340693e+05       5.253843e+05\n",
      "min         1.154100e+04       1.154100e+04       1.154100e+04\n",
      "25%         1.354282e+05       1.028310e+05       1.279618e+05\n",
      "50%         3.672335e+05       2.715960e+05       3.415810e+05\n",
      "75%         4.568915e+05       5.186000e+05       8.490842e+05\n",
      "max         3.995951e+06       3.995951e+06       3.995951e+06\n",
      "Statistics for columns: CAPITAL_OUTLAY_EXPENDITURE\n",
      "       CAPITAL_OUTLAY_EXPENDITURE  CAPITAL_OUTLAY_EXPENDITURE  \\\n",
      "count                1.492000e+03                1.280000e+03   \n",
      "mean                 9.027693e+05                9.027693e+05   \n",
      "std                  1.229564e+06                1.327562e+06   \n",
      "min                  1.270800e+04                1.270800e+04   \n",
      "25%                  2.163398e+05                1.815645e+05   \n",
      "50%                  6.482175e+05                5.102595e+05   \n",
      "75%                  9.027693e+05                9.668515e+05   \n",
      "max                  1.022366e+07                1.022366e+07   \n",
      "\n",
      "       CAPITAL_OUTLAY_EXPENDITURE  \n",
      "count                1.492000e+03  \n",
      "mean                 1.033524e+06  \n",
      "std                  1.272901e+06  \n",
      "min                  1.270800e+04  \n",
      "25%                  2.163398e+05  \n",
      "50%                  6.436235e+05  \n",
      "75%                  1.717212e+06  \n",
      "max                  1.022366e+07  \n",
      "Statistics for columns: GRADES_PK_G\n",
      "         GRADES_PK_G    GRADES_PK_G    GRADES_PK_G\n",
      "count    1492.000000    1319.000000    1492.000000\n",
      "mean    17601.614102   17601.614102   15926.059316\n",
      "std     28221.111094   30016.166447   28669.479212\n",
      "min         0.000000       0.000000       0.000000\n",
      "25%      2449.000000    2021.000000    1544.000000\n",
      "50%     10505.000000    8106.000000    5910.500000\n",
      "75%     19149.250000   22295.000000   19561.000000\n",
      "max    250911.000000  250911.000000  250911.000000\n",
      "Statistics for columns: GRADES_KG_G\n",
      "         GRADES_KG_G    GRADES_KG_G    GRADES_KG_G\n",
      "count    1492.000000    1360.000000    1492.000000\n",
      "mean    63746.761029   63746.761029   59021.465818\n",
      "std     76572.547833   80205.138143   78271.025323\n",
      "min       544.000000     544.000000     544.000000\n",
      "25%     14016.000000   11745.000000    9926.750000\n",
      "50%     48897.000000   41597.500000   38507.000000\n",
      "75%     70372.750000   73865.250000   70748.750000\n",
      "max    530531.000000  530531.000000  530531.000000\n",
      "Statistics for columns: GRADES_4_G\n",
      "          GRADES_4_G     GRADES_4_G     GRADES_4_G\n",
      "count    1492.000000    1361.000000    1492.000000\n",
      "mean    64538.927259   64538.927259   59797.646113\n",
      "std     76684.998585   80293.387625   78406.899202\n",
      "min       633.000000     633.000000     633.000000\n",
      "25%     15195.500000   13739.000000   10117.250000\n",
      "50%     49884.500000   43272.000000   38280.500000\n",
      "75%     71814.250000   75481.000000   72310.250000\n",
      "max    493415.000000  493415.000000  493415.000000\n",
      "Statistics for columns: GRADES_8_G\n",
      "          GRADES_8_G     GRADES_8_G     GRADES_8_G\n",
      "count    1492.000000    1361.000000    1492.000000\n",
      "mean    64271.057311   64271.057311   59511.380027\n",
      "std     75364.301721   78910.545776   77123.573668\n",
      "min       437.000000     437.000000     437.000000\n",
      "25%     15682.750000   13342.000000   10252.000000\n",
      "50%     49571.000000   43339.000000   38114.500000\n",
      "75%     72131.000000   76566.000000   72598.250000\n",
      "max    500143.000000  500143.000000  500143.000000\n",
      "Statistics for columns: GRADES_12_G\n",
      "         GRADES_12_G   GRADES_12_G    GRADES_12_G\n",
      "count    1492.000000    1361.00000    1492.000000\n",
      "mean    54268.924320   54268.92432   50207.239276\n",
      "std     64838.328605   67889.27623   66309.867155\n",
      "min       311.000000     311.00000     311.000000\n",
      "25%     13437.000000   10919.00000    8951.000000\n",
      "50%     39566.000000   36735.00000   33279.000000\n",
      "75%     64616.250000   67460.00000   64920.500000\n",
      "max    498403.000000  498403.00000  498403.000000\n",
      "Statistics for columns: GRADES_1_8_G\n",
      "       GRADES_1_8_G  GRADES_1_8_G  GRADES_1_8_G\n",
      "count  1.492000e+03  1.361000e+03  1.492000e+03\n",
      "mean   5.192140e+05  5.192140e+05  4.810102e+05\n",
      "std    6.147133e+05  6.436384e+05  6.286622e+05\n",
      "min    4.878000e+03  4.878000e+03  4.878000e+03\n",
      "25%    1.211522e+05  1.106260e+05  8.127325e+04\n",
      "50%    4.015865e+05  3.457750e+05  3.097340e+05\n",
      "75%    5.749118e+05  6.119050e+05  5.783400e+05\n",
      "max    3.929869e+06  3.929869e+06  3.929869e+06\n",
      "Statistics for columns: GRADES_9_12_G\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       GRADES_9_12_G  GRADES_9_12_G  GRADES_9_12_G\n",
      "count   1.492000e+03   1.361000e+03   1.492000e+03\n",
      "mean    2.470714e+05   2.470714e+05   2.286678e+05\n",
      "std     2.938773e+05   3.077056e+05   3.005815e+05\n",
      "min     1.808000e+03   1.808000e+03   1.808000e+03\n",
      "25%     5.919750e+04   5.147100e+04   3.950675e+04\n",
      "50%     1.817010e+05   1.642600e+05   1.472355e+05\n",
      "75%     2.825390e+05   2.905020e+05   2.843505e+05\n",
      "max     2.013687e+06   2.013687e+06   2.013687e+06\n",
      "Statistics for columns: GRADES_ALL_G\n",
      "       GRADES_ALL_G  GRADES_ALL_G  GRADES_ALL_G\n",
      "count  1.492000e+03  1.319000e+03  1.492000e+03\n",
      "mean   8.024415e+05  8.024415e+05  7.478782e+05\n",
      "std    9.126522e+05  9.707031e+05  9.291585e+05\n",
      "min    7.254000e+03  7.254000e+03  7.254000e+03\n",
      "25%    2.293578e+05  1.810650e+05  1.718665e+05\n",
      "50%    6.473260e+05  5.503420e+05  4.591248e+05\n",
      "75%    8.724220e+05  9.282755e+05  8.860948e+05\n",
      "max    5.944746e+06  5.944746e+06  5.944746e+06\n"
     ]
    }
   ],
   "source": [
    "# Use .describe to compare each of the columns where imputation was used!\n",
    "for column in imputable_columns:\n",
    "    print(\"Statistics for columns: {}\".format(column))\n",
    "    print(pd.concat([educationdup_df[column], educationdup2_df[column], educationdup3_df[column]], axis=1).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
