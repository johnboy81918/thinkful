{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data (NBA box score data over 6 seasons)\n",
    "\n",
    "df = pd.read_csv('2012-18_teamBoxScore.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create net values for all counting metrics, these will provide many of the features (and the target)\n",
    "\n",
    "df['net_points'] = df['teamPTS'] - df['opptPTS'] # this is the target! can we predict the net point differential?\n",
    "df['net_assists'] = df['teamAST'] - df['opptAST']\n",
    "df['net_turnovers'] = df['teamTO'] - df['opptTO']\n",
    "df['net_steals'] = df['teamSTL'] - df['opptSTL']\n",
    "df['net_blocks'] = df['teamBLK'] - df['opptBLK']\n",
    "df['net_fouls'] = df['teamPF'] - df['opptPF']\n",
    "df['net_rebounds'] = df['teamTRB'] - df['opptTRB']\n",
    "df['net_fourth'] = df['teamPTS4'] - df['opptPTS4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>net_points</td>    <th>  R-squared:         </th> <td>   0.652</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.652</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3954.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 07 Aug 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:18:56</td>     <th>  Log-Likelihood:    </th> <td> -51770.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 14758</td>      <th>  AIC:               </th> <td>1.036e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 14750</td>      <th>  BIC:               </th> <td>1.036e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>-6.939e-18</td> <td>    0.067</td> <td>-1.04e-16</td> <td> 1.000</td> <td>   -0.130</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>net_assists</th>   <td>    0.8972</td> <td>    0.011</td> <td>   83.936</td> <td> 0.000</td> <td>    0.876</td> <td>    0.918</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>net_turnovers</th> <td>   -0.5903</td> <td>    0.021</td> <td>  -28.181</td> <td> 0.000</td> <td>   -0.631</td> <td>   -0.549</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>net_steals</th>    <td>    0.4137</td> <td>    0.025</td> <td>   16.821</td> <td> 0.000</td> <td>    0.365</td> <td>    0.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>net_blocks</th>    <td>    0.5534</td> <td>    0.019</td> <td>   28.830</td> <td> 0.000</td> <td>    0.516</td> <td>    0.591</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>net_fouls</th>     <td>   -0.2423</td> <td>    0.013</td> <td>  -18.570</td> <td> 0.000</td> <td>   -0.268</td> <td>   -0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>net_rebounds</th>  <td>    0.6756</td> <td>    0.009</td> <td>   79.168</td> <td> 0.000</td> <td>    0.659</td> <td>    0.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>net_fourth</th>    <td>    0.2718</td> <td>    0.009</td> <td>   28.914</td> <td> 0.000</td> <td>    0.253</td> <td>    0.290</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 5.689</td> <th>  Durbin-Watson:     </th> <td>   2.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.058</td> <th>  Jarque-Bera (JB):  </th> <td>   4.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.000</td> <th>  Prob(JB):          </th> <td>  0.0835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.090</td> <th>  Cond. No.          </th> <td>    9.63</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             net_points   R-squared:                       0.652\n",
       "Model:                            OLS   Adj. R-squared:                  0.652\n",
       "Method:                 Least Squares   F-statistic:                     3954.\n",
       "Date:                Wed, 07 Aug 2019   Prob (F-statistic):               0.00\n",
       "Time:                        21:18:56   Log-Likelihood:                -51770.\n",
       "No. Observations:               14758   AIC:                         1.036e+05\n",
       "Df Residuals:                   14750   BIC:                         1.036e+05\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const         -6.939e-18      0.067  -1.04e-16      1.000      -0.130       0.130\n",
       "net_assists       0.8972      0.011     83.936      0.000       0.876       0.918\n",
       "net_turnovers    -0.5903      0.021    -28.181      0.000      -0.631      -0.549\n",
       "net_steals        0.4137      0.025     16.821      0.000       0.365       0.462\n",
       "net_blocks        0.5534      0.019     28.830      0.000       0.516       0.591\n",
       "net_fouls        -0.2423      0.013    -18.570      0.000      -0.268      -0.217\n",
       "net_rebounds      0.6756      0.009     79.168      0.000       0.659       0.692\n",
       "net_fourth        0.2718      0.009     28.914      0.000       0.253       0.290\n",
       "==============================================================================\n",
       "Omnibus:                        5.689   Durbin-Watson:                   2.996\n",
       "Prob(Omnibus):                  0.058   Jarque-Bera (JB):                4.967\n",
       "Skew:                           0.000   Prob(JB):                       0.0835\n",
       "Kurtosis:                       3.090   Cond. No.                         9.63\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try plain OLS to see what we're working with\n",
    "\n",
    "X = df[['net_assists', 'net_turnovers', 'net_steals', 'net_blocks', 'net_fouls', 'net_rebounds', 'net_fourth']]\n",
    "Y = df['net_points']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "results = sm.OLS(Y, X).fit()\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>net_points</td>    <th>  R-squared:         </th> <td>   0.650</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.650</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3133.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 07 Aug 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:18:56</td>     <th>  Log-Likelihood:    </th> <td> -41412.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 11806</td>      <th>  AIC:               </th> <td>8.284e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 11798</td>      <th>  BIC:               </th> <td>8.290e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>         <td>   -0.0468</td> <td>    0.074</td> <td>   -0.630</td> <td> 0.529</td> <td>   -0.193</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>net_assists</th>   <td>    0.8938</td> <td>    0.012</td> <td>   74.617</td> <td> 0.000</td> <td>    0.870</td> <td>    0.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>net_turnovers</th> <td>   -0.6025</td> <td>    0.023</td> <td>  -25.657</td> <td> 0.000</td> <td>   -0.649</td> <td>   -0.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>net_steals</th>    <td>    0.4060</td> <td>    0.027</td> <td>   14.778</td> <td> 0.000</td> <td>    0.352</td> <td>    0.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>net_blocks</th>    <td>    0.5469</td> <td>    0.022</td> <td>   25.362</td> <td> 0.000</td> <td>    0.505</td> <td>    0.589</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>net_fouls</th>     <td>   -0.2468</td> <td>    0.015</td> <td>  -16.956</td> <td> 0.000</td> <td>   -0.275</td> <td>   -0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>net_rebounds</th>  <td>    0.6727</td> <td>    0.010</td> <td>   70.078</td> <td> 0.000</td> <td>    0.654</td> <td>    0.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>net_fourth</th>    <td>    0.2764</td> <td>    0.011</td> <td>   26.280</td> <td> 0.000</td> <td>    0.256</td> <td>    0.297</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.222</td> <th>  Durbin-Watson:     </th> <td>   2.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.121</td> <th>  Jarque-Bera (JB):  </th> <td>   4.427</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.013</td> <th>  Prob(JB):          </th> <td>   0.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.091</td> <th>  Cond. No.          </th> <td>    9.60</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             net_points   R-squared:                       0.650\n",
       "Model:                            OLS   Adj. R-squared:                  0.650\n",
       "Method:                 Least Squares   F-statistic:                     3133.\n",
       "Date:                Wed, 07 Aug 2019   Prob (F-statistic):               0.00\n",
       "Time:                        21:18:56   Log-Likelihood:                -41412.\n",
       "No. Observations:               11806   AIC:                         8.284e+04\n",
       "Df Residuals:                   11798   BIC:                         8.290e+04\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "const            -0.0468      0.074     -0.630      0.529      -0.193       0.099\n",
       "net_assists       0.8938      0.012     74.617      0.000       0.870       0.917\n",
       "net_turnovers    -0.6025      0.023    -25.657      0.000      -0.649      -0.556\n",
       "net_steals        0.4060      0.027     14.778      0.000       0.352       0.460\n",
       "net_blocks        0.5469      0.022     25.362      0.000       0.505       0.589\n",
       "net_fouls        -0.2468      0.015    -16.956      0.000      -0.275      -0.218\n",
       "net_rebounds      0.6727      0.010     70.078      0.000       0.654       0.692\n",
       "net_fourth        0.2764      0.011     26.280      0.000       0.256       0.297\n",
       "==============================================================================\n",
       "Omnibus:                        4.222   Durbin-Watson:                   2.027\n",
       "Prob(Omnibus):                  0.121   Jarque-Bera (JB):                4.427\n",
       "Skew:                          -0.013   Prob(JB):                        0.109\n",
       "Kurtosis:                       3.091   Cond. No.                         9.60\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set aside 20% as test set for OLS\n",
    "\n",
    "X = df[['net_assists', 'net_turnovers', 'net_steals', 'net_blocks', 'net_fouls', 'net_rebounds', 'net_fourth']]\n",
    "Y = df['net_points']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "\n",
    "results = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try the whole suite of OLS methods for fun!\n",
    "\n",
    "X = df[['net_assists', 'net_turnovers', 'net_steals', 'net_blocks', 'net_fouls', 'net_rebounds', 'net_fourth']]\n",
    "Y = df['net_points']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "\n",
    "alphas = [np.power(10.0,p) for p in np.arange(-20,40,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the model in training set is: 0.6509743544097176\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.6572757151443493\n",
      "Mean absolute error of the prediction is: 6.4297060450247105\n",
      "Mean squared error of the prediction is: 64.52294365389263\n",
      "Root mean squared error of the prediction is: 8.03261748459944\n",
      "Mean absolute percentage error of the prediction is: 96.44565146624794\n"
     ]
    }
   ],
   "source": [
    "lrm = LinearRegression()\n",
    "\n",
    "lrm.fit(X_train, y_train)\n",
    "\n",
    "y_preds_train = lrm.predict(X_train)\n",
    "y_preds_test = lrm.predict(X_test)\n",
    "\n",
    "print(\"R-squared of the model in training set is: {}\".format(lrm.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in test set is: {}\".format(lrm.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11079.125318416161, tolerance: 177.0547813214748\n",
      "  tol, rng, random, positive)\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10948.237045485934, tolerance: 177.5504215352039\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 0.01\n",
      "R-squared of the model in training set is: 0.6509742473856758\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.6572778063181777\n",
      "Mean absolute error of the prediction is: 6.42968676960871\n",
      "Mean squared error of the prediction is: 64.5225499593193\n",
      "Root mean squared error of the prediction is: 8.032592978566717\n",
      "Mean absolute percentage error of the prediction is: 96.43110347142402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 140315.09270454693, tolerance: 177.5504215352039\n",
      "  tol, rng, random, positive)\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 109527.73468991357, tolerance: 179.22625691900427\n",
      "  tol, rng, random, positive)\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 309663.30516289436, tolerance: 179.22625691900427\n",
      "  tol, rng, random, positive)\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 310025.4255193899, tolerance: 179.22625691900427\n",
      "  tol, rng, random, positive)\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 310061.64919348573, tolerance: 179.22625691900427\n",
      "  tol, rng, random, positive)\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11030.560065597878, tolerance: 176.09883148756006\n",
      "  tol, rng, random, positive)\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38160.995375307044, tolerance: 176.09883148756006\n",
      "  tol, rng, random, positive)\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37724.18225310987, tolerance: 175.3268057596604\n",
      "  tol, rng, random, positive)\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37724.18225310906, tolerance: 175.3268057596604\n",
      "  tol, rng, random, positive)\n"
     ]
    }
   ],
   "source": [
    "lasso_cv = LassoCV(alphas=alphas, cv=5)\n",
    "\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "y_preds_train = lasso_cv.predict(X_train)\n",
    "y_preds_test = lasso_cv.predict(X_test)\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(lasso_cv.alpha_))\n",
    "print(\"R-squared of the model in training set is: {}\".format(lasso_cv.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in test set is: {}\".format(lasso_cv.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.19053e-27): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.92052e-27): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.96267e-27): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.99273e-27): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.04115e-27): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.19053e-26): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.92052e-26): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.96267e-26): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.99273e-26): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.04115e-26): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.19053e-25): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.92052e-25): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.96267e-25): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.99273e-25): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.04115e-25): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.19053e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.92052e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.96267e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.99273e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.04115e-24): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.19053e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.92052e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.96267e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.99273e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.04115e-23): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.19053e-22): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.92052e-22): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.96267e-22): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.99273e-22): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.04115e-22): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.19053e-21): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.92052e-21): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.96267e-21): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.99273e-21): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.04115e-21): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.19053e-20): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.92052e-20): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.96267e-20): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.99273e-20): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.04115e-20): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.19053e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.92052e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.96267e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.99273e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.04115e-19): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.19053e-18): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.92052e-18): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.96267e-18): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.99273e-18): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.04115e-18): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.19053e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.92052e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.96267e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=7.99273e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:147: LinAlgWarning: Ill-conditioned matrix (rcond=8.04115e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 1000.0\n",
      "R-squared of the model in training set is: 0.6509721284242674\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.6572651482619425\n",
      "Mean absolute error of the prediction is: 6.429708884694992\n",
      "Mean squared error of the prediction is: 64.52493302665746\n",
      "Root mean squared error of the prediction is: 8.032741314561141\n",
      "Mean absolute percentage error of the prediction is: 96.37304464308406\n"
     ]
    }
   ],
   "source": [
    "ridge_cv = RidgeCV(alphas=alphas, cv=5)\n",
    "\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "y_preds_train = ridge_cv.predict(X_train)\n",
    "y_preds_test = ridge_cv.predict(X_test)\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(ridge_cv.alpha_))\n",
    "print(\"R-squared of the model in training set is: {}\".format(ridge_cv.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in test set is: {}\".format(ridge_cv.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value is: 0.01\n",
      "R-squared of the model in training set is: 0.6509742943239358\n",
      "-----Test set statistics-----\n",
      "R-squared of the model in test set is: 0.6572762629971989\n",
      "Mean absolute error of the prediction is: 6.429695563284882\n",
      "Mean squared error of the prediction is: 64.522840512446\n",
      "Root mean squared error of the prediction is: 8.032611064432661\n",
      "Mean absolute percentage error of the prediction is: 96.43406915564965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1803.3739930732409, tolerance: 177.5504215352039\n",
      "  tol, rng, random, positive)\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 66923.65793476684, tolerance: 177.5504215352039\n",
      "  tol, rng, random, positive)\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 119115.6143595294, tolerance: 177.5504215352039\n",
      "  tol, rng, random, positive)\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41002.139863414224, tolerance: 179.22625691900427\n",
      "  tol, rng, random, positive)\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 164010.64407250512, tolerance: 179.22625691900427\n",
      "  tol, rng, random, positive)\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 310063.6616780461, tolerance: 179.22625691900427\n",
      "  tol, rng, random, positive)\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1532.6617544930195, tolerance: 176.09883148756006\n",
      "  tol, rng, random, positive)\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 61161.39713228721, tolerance: 176.09883148756006\n",
      "  tol, rng, random, positive)\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 60303.44597729988, tolerance: 175.3268057596604\n",
      "  tol, rng, random, positive)\n",
      "c:\\users\\johnsteph\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:471: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 162642.51312802522, tolerance: 175.3268057596604\n",
      "  tol, rng, random, positive)\n"
     ]
    }
   ],
   "source": [
    "elasticnet_cv = ElasticNetCV(alphas=alphas, cv=5)\n",
    "\n",
    "elasticnet_cv.fit(X_train, y_train)\n",
    "\n",
    "y_preds_train = elasticnet_cv.predict(X_train)\n",
    "y_preds_test = elasticnet_cv.predict(X_test)\n",
    "\n",
    "print(\"Best alpha value is: {}\".format(elasticnet_cv.alpha_))\n",
    "print(\"R-squared of the model in training set is: {}\".format(elasticnet_cv.score(X_train, y_train)))\n",
    "print(\"-----Test set statistics-----\")\n",
    "print(\"R-squared of the model in test set is: {}\".format(elasticnet_cv.score(X_test, y_test)))\n",
    "print(\"Mean absolute error of the prediction is: {}\".format(mean_absolute_error(y_test, y_preds_test)))\n",
    "print(\"Mean squared error of the prediction is: {}\".format(mse(y_test, y_preds_test)))\n",
    "print(\"Root mean squared error of the prediction is: {}\".format(rmse(y_test, y_preds_test)))\n",
    "print(\"Mean absolute percentage error of the prediction is: {}\".format(np.mean(np.abs((y_test - y_preds_test) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite python's many complaints about convergence, the OLS methods all performed very similarly to each other, explaining 2/3 of the variance with just a few features! Let's move on to KNN and see if it performs any better..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted Accuracy: 0.63 (+/- 0.03)\n",
      "Weighted Accuracy: 0.63 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "# unweighted\n",
    "knn = neighbors.KNeighborsRegressor(n_neighbors=25)\n",
    "X = df[['net_assists', 'net_turnovers', 'net_steals', 'net_blocks', 'net_fouls', 'net_rebounds', 'net_fourth']]\n",
    "Y = df['net_points']\n",
    "knn.fit(X, Y)\n",
    "\n",
    "# weighted\n",
    "knn_w = neighbors.KNeighborsRegressor(n_neighbors=25, weights='distance')\n",
    "X = df[['net_assists', 'net_turnovers', 'net_steals', 'net_blocks', 'net_fouls', 'net_rebounds', 'net_fourth']]\n",
    "Y = df['net_points']\n",
    "knn_w.fit(X, Y)\n",
    "\n",
    "score = cross_val_score(knn, X, Y, cv=5)\n",
    "print(\"Unweighted Accuracy: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))\n",
    "score_w = cross_val_score(knn_w, X, Y, cv=5)\n",
    "print(\"Weighted Accuracy: %0.2f (+/- %0.2f)\" % (score_w.mean(), score_w.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the KNN models is fairly similar to the r-squared of the OLS models (not that they measure exactly the same thing, but for purposes of this exercise it's a good baseline). That being the case, there's no particularly compelling reason to prefer one model to another given this basic feature set.\n",
    "\n",
    "Adding in some intuition leads me to believe that KNN is probably better than OLS for this particular application, given the likelihood of multicollinearity between some of the chosen features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
