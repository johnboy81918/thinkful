{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn import neighbors, tree, ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from statsmodels.tools.eval_measures import mse, rmse\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "df = pd.read_csv('RegularSeasonDetailedResults.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training set from this data\n",
    "\n",
    "training_set = pd.DataFrame()\n",
    "\n",
    "training_set['net_fgm'] = df['WFGM'] - df['LFGM']\n",
    "training_set['net_fga'] = df['WFGA'] - df['LFGA']\n",
    "training_set['net_fgm3'] = df['WFGM3'] - df['LFGM3']\n",
    "training_set['net_fga3'] = df['WFGA3'] - df['LFGA3']\n",
    "training_set['net_ftm'] = df['WFTM'] - df['LFTM']\n",
    "training_set['net_fta'] = df['WFTA'] - df['LFTA']\n",
    "training_set['net_or'] = df['WOR'] - df['LOR']\n",
    "training_set['net_dr'] = df['WDR'] - df['LDR']\n",
    "training_set['net_tr'] = df['WOR'] + df['WDR'] - df['LOR'] - df['LDR']\n",
    "training_set['net_ast'] = df['WAst'] - df['LAst']\n",
    "training_set['net_to'] = df['WTO'] - df['LTO']\n",
    "training_set['net_stl'] = df['WStl'] - df['LStl']\n",
    "training_set['net_blk'] = df['WBlk'] - df['LBlk']\n",
    "training_set['net_pf'] = df['WPF'] - df['LPF']\n",
    "training_set['win'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_df = -training_set\n",
    "inverse_df['win'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the final version of the training set\n",
    "# x_train = all columns except 'win'\n",
    "# y_train = win column\n",
    "\n",
    "final_df = training_set.append(inverse_df)\n",
    "\n",
    "x_train = final_df.drop(columns = 'win')\n",
    "y_train = final_df['win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = df.loc[df['Season'] == 2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018_net = pd.DataFrame()\n",
    "\n",
    "df_2018_net['teamid'] = df_2018['WTeamID']\n",
    "df_2018_net['net_fgm'] = df_2018['WFGM'] - df_2018['LFGM']\n",
    "df_2018_net['net_fga'] = df_2018['WFGA'] - df_2018['LFGA']\n",
    "df_2018_net['net_fgm3'] = df_2018['WFGM3'] - df_2018['LFGM3']\n",
    "df_2018_net['net_fga3'] = df_2018['WFGA3'] - df_2018['LFGA3']\n",
    "df_2018_net['net_ftm'] = df_2018['WFTM'] - df_2018['LFTM']\n",
    "df_2018_net['net_fta'] = df_2018['WFTA'] - df_2018['LFTA']\n",
    "df_2018_net['net_or'] = df_2018['WOR'] - df_2018['LOR']\n",
    "df_2018_net['net_dr'] = df_2018['WDR'] - df_2018['LDR']\n",
    "df_2018_net['net_tr'] = df_2018['WOR'] + df_2018['WDR'] - df_2018['LOR'] - df_2018['LDR']\n",
    "df_2018_net['net_ast'] = df_2018['WAst'] - df_2018['LAst']\n",
    "df_2018_net['net_to'] = df_2018['WTO'] - df_2018['LTO']\n",
    "df_2018_net['net_stl'] = df_2018['WStl'] - df_2018['LStl']\n",
    "df_2018_net['net_blk'] = df_2018['WBlk'] - df_2018['LBlk']\n",
    "df_2018_net['net_pf'] = df_2018['WPF'] - df_2018['LPF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018_inverse = -df_2018_net\n",
    "df_2018_inverse['teamid'] = df_2018['LTeamID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_2018_df = df_2018_net.append(df_2018_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = aggregate_2018_df.groupby('teamid')['net_fgm', 'net_fga', 'net_fgm3', 'net_fga3', 'net_ftm', 'net_fta', 'net_or',\n",
    "                                             'net_dr', 'net_tr', 'net_ast', 'net_to', 'net_stl', 'net_blk', 'net_pf'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('SampleSubmissionStage2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create final dataframe to submit into the models for prediction\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "test_df['team1'] = submission_df['ID'].str[5:9]\n",
    "test_df['team2'] = submission_df['ID'].str[10:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_copy = test_df\n",
    "\n",
    "for index, row in test_copy.iterrows():\n",
    "    test_copy.loc[index, 'net_fgm'] = test_data.loc[int(row['team1']), 'net_fgm'] - test_data.loc[int(row['team2']), 'net_fgm']\n",
    "    test_copy.loc[index, 'net_fga'] = test_data.loc[int(row['team1']), 'net_fga'] - test_data.loc[int(row['team2']), 'net_fga']\n",
    "    test_copy.loc[index, 'net_fgm3'] = test_data.loc[int(row['team1']), 'net_fgm3'] - test_data.loc[int(row['team2']), 'net_fgm3']\n",
    "    test_copy.loc[index, 'net_fga3'] = test_data.loc[int(row['team1']), 'net_fga3'] - test_data.loc[int(row['team2']), 'net_fga3']\n",
    "    test_copy.loc[index, 'net_ftm'] = test_data.loc[int(row['team1']), 'net_ftm'] - test_data.loc[int(row['team2']), 'net_ftm']\n",
    "    test_copy.loc[index, 'net_fta'] = test_data.loc[int(row['team1']), 'net_fta'] - test_data.loc[int(row['team2']), 'net_fta']\n",
    "    test_copy.loc[index, 'net_or'] = test_data.loc[int(row['team1']), 'net_or'] - test_data.loc[int(row['team2']), 'net_or']\n",
    "    test_copy.loc[index, 'net_dr'] = test_data.loc[int(row['team1']), 'net_dr'] - test_data.loc[int(row['team2']), 'net_dr']\n",
    "    test_copy.loc[index, 'net_tr'] = test_data.loc[int(row['team1']), 'net_tr'] - test_data.loc[int(row['team2']), 'net_tr']\n",
    "    test_copy.loc[index, 'net_ast'] = test_data.loc[int(row['team1']), 'net_ast'] - test_data.loc[int(row['team2']), 'net_ast']\n",
    "    test_copy.loc[index, 'net_to'] = test_data.loc[int(row['team1']), 'net_to'] - test_data.loc[int(row['team2']), 'net_to']\n",
    "    test_copy.loc[index, 'net_stl'] = test_data.loc[int(row['team1']), 'net_stl'] - test_data.loc[int(row['team2']), 'net_stl']\n",
    "    test_copy.loc[index, 'net_blk'] = test_data.loc[int(row['team1']), 'net_blk'] - test_data.loc[int(row['team2']), 'net_blk']\n",
    "    test_copy.loc[index, 'net_pf'] = test_data.loc[int(row['team1']), 'net_pf'] - test_data.loc[int(row['team2']), 'net_pf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting classifier, 2 deep trees, 500 iterations\n",
    "\n",
    "gbc2d500 = GradientBoostingClassifier(loss = 'deviance',\n",
    "                                     n_estimators = 500,\n",
    "                                     max_depth=2)\n",
    "gbc2d500.fit(x_train, y_train)\n",
    "gbc2d500_test = gbc2d500.predict(test_copy.drop(columns = ['team1', 'team2']))\n",
    "gbc2d500_submission = submission_df\n",
    "gbc2d500_submission['Pred'] = gbc2d500_test\n",
    "gbc2d500_submission.to_csv('gbc2d500_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting classifier, 2 deep trees, 100 iterations\n",
    "\n",
    "gbc2d100 = GradientBoostingClassifier(loss = 'deviance',\n",
    "                                     n_estimators = 100,\n",
    "                                     max_depth=2)\n",
    "gbc2d100.fit(x_train, y_train)\n",
    "gbc2d100_test = gbc2d100.predict(test_copy.drop(columns = ['team1', 'team2']))\n",
    "gbc2d100_submission = submission_df\n",
    "gbc2d100_submission['Pred'] = gbc2d100_test\n",
    "gbc2d100_submission.to_csv('gbc2d100_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting classifier, 3 deep trees, 500 iterations\n",
    "\n",
    "gbc3d500 = GradientBoostingClassifier(loss = 'deviance',\n",
    "                                     n_estimators = 500,\n",
    "                                     max_depth=3)\n",
    "gbc3d500.fit(x_train, y_train)\n",
    "gbc3d500_test = gbc3d500.predict(test_copy.drop(columns = ['team1', 'team2']))\n",
    "gbc3d500_submission = submission_df\n",
    "gbc3d500_submission['Pred'] = gbc3d500_test\n",
    "gbc3d500_submission.to_csv('gbc3d500_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting classifier, 3 deep trees, 100 iterations\n",
    "\n",
    "gbc3d100 = GradientBoostingClassifier(loss = 'deviance',\n",
    "                                     n_estimators = 100,\n",
    "                                     max_depth=3)\n",
    "gbc3d100.fit(x_train, y_train)\n",
    "gbc3d100_test = gbc3d100.predict(test_copy.drop(columns = ['team1', 'team2']))\n",
    "gbc3d100_submission = submission_df\n",
    "gbc3d100_submission['Pred'] = gbc3d100_test\n",
    "gbc3d100_submission.to_csv('gbc3d100_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting regressor, 2 deep trees, 100 iterations\n",
    "\n",
    "gbr2d100 = GradientBoostingRegressor(n_estimators = 100,\n",
    "                                     max_depth=2)\n",
    "gbr2d100.fit(x_train, y_train)\n",
    "gbr2d100_test = gbr2d100.predict(test_copy.drop(columns = ['team1', 'team2']))\n",
    "gbr2d100_bounded = np.clip(gbr2d100_test, 0, 1)\n",
    "gbr2d100_submission = submission_df\n",
    "gbr2d100_submission['Pred'] = gbr2d100_bounded\n",
    "gbr2d100_submission.to_csv('gbr2d100_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting regressor, 2 deep trees, 500 iterations\n",
    "\n",
    "gbr2d500 = GradientBoostingRegressor(n_estimators = 500,\n",
    "                                     max_depth=2)\n",
    "gbr2d500.fit(x_train, y_train)\n",
    "gbr2d500_test = gbr2d500.predict(test_copy.drop(columns = ['team1', 'team2']))\n",
    "gbr2d500_bounded = np.clip(gbr2d500_test, 0, 1)\n",
    "gbr2d500_submission = submission_df\n",
    "gbr2d500_submission['Pred'] = gbr2d500_bounded\n",
    "gbr2d500_submission.to_csv('gbr2d500_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting regressor, 3 deep trees, 100 iterations\n",
    "\n",
    "gbr3d100 = GradientBoostingRegressor(n_estimators = 100,\n",
    "                                     max_depth=3)\n",
    "gbr3d100.fit(x_train, y_train)\n",
    "gbr3d100_test = gbr3d100.predict(test_copy.drop(columns = ['team1', 'team2']))\n",
    "gbr3d100_bounded = np.clip(gbr3d100_test, 0, 1)\n",
    "gbr3d100_submission = submission_df\n",
    "gbr3d100_submission['Pred'] = gbr3d100_bounded\n",
    "gbr3d100_submission.to_csv('gbr3d100_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosting regressor, 3 deep trees, 500 iterations\n",
    "\n",
    "gbr3d500 = GradientBoostingRegressor(n_estimators = 500,\n",
    "                                     max_depth=3)\n",
    "gbr3d500.fit(x_train, y_train)\n",
    "gbr3d500_test = gbr3d500.predict(test_copy.drop(columns = ['team1', 'team2']))\n",
    "gbr3d500_bounded = np.clip(gbr3d500_test, 0, 1)\n",
    "gbr3d500_submission = submission_df\n",
    "gbr3d500_submission['Pred'] = gbr3d500_bounded\n",
    "gbr3d500_submission.to_csv('gbr3d500_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
